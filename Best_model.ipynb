{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9108,
     "status": "ok",
     "timestamp": 1524304291827,
     "user": {
      "displayName": "Łukasz Zawieska",
      "photoUrl": "//lh4.googleusercontent.com/-SOS7Ol5qfEA/AAAAAAAAAAI/AAAAAAAABh4/xJ9cAj7pBag/s50-c-k-no/photo.jpg",
      "userId": "112181072187986880314"
     },
     "user_tz": -120
    },
    "id": "M3esxoVFVqZ4",
    "outputId": "6a4068d4-30e4-4756-c94a-59a81bb49645"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Activation, Dropout, Flatten, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import  RandomNormal\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "# Checking if GPU is available\n",
    "tf.test.gpu_device_name()\n",
    "tf.test.is_gpu_available(cuda_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1763,
     "status": "ok",
     "timestamp": 1524231801053,
     "user": {
      "displayName": "Łukasz Zawieska",
      "photoUrl": "//lh4.googleusercontent.com/-SOS7Ol5qfEA/AAAAAAAAAAI/AAAAAAAABh4/xJ9cAj7pBag/s50-c-k-no/photo.jpg",
      "userId": "112181072187986880314"
     },
     "user_tz": -120
    },
    "id": "MoLNdrj2Us6r",
    "outputId": "ce45654a-3fe5-400b-c639-9f1531306be6"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../fer2013.csv\")\n",
    "\n",
    "emotions_names = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "data['emotion_name'] = data['emotion'].map(emotions_names)\n",
    "\n",
    "pixels_values = data.pixels.str.split(\" \").tolist()\n",
    "pixels_values = pd.DataFrame(pixels_values, dtype=int)\n",
    "images = pixels_values.values\n",
    "images = images.astype(np.float)\n",
    "\n",
    "test_idx_start = 32298\n",
    "images_test = images[test_idx_start:]\n",
    "\n",
    "\n",
    "# Function for displaying 15 random images\n",
    "def show(imgs, emotion_nms_org = None, emotion_nms_pred = None, random = True, indices = None):\n",
    "    \"\"\" \n",
    "    Function displaying 15 randomly chosen images. Arguments:\n",
    "    \n",
    "    imgs:  Source of images\n",
    "    \n",
    "    emotion_nms_org: Default \"None\", if specified, should be a Pandas Series object consisting of emotion names. \n",
    "                     As a result, emotion name will be displayed above every image.\n",
    "    \n",
    "    emotion_nms_pred: Default \"None\", if specified should be a Pandas Series object with predicted emotion names.\n",
    "                      As a result, emotion name will be displayed above image.\n",
    "    \n",
    "    random: Defult \"True\", indices will be randomly drawn from “discrete uniform” distribution starting \n",
    "            at 0 up to max(len(imgs) otherwise randomly chosen from values passed into \"indices\" argument.\n",
    "    \n",
    "    indices: Default \"None\", if specified \"random\" should be set to \"False\" to draw random images from the variable\n",
    "            passed into \"indices\" argument starting at min(len(indices) up to max(len(indices) and not using\n",
    "            \"discrete uniform\" distribution. \n",
    "    \"\"\"\n",
    "    \n",
    "    if random == True:\n",
    "        indices = np.random.randint(0, len(imgs), size = 16)\n",
    "    else:\n",
    "        indices = np.random.randint(indices.min(), indices.max(), size = 16)\n",
    "    plt.figure(figsize=(20, 14)) \n",
    "    for index, number in enumerate(indices):         \n",
    "        if (isinstance(emotion_nms_org, type(None)) & isinstance(emotion_nms_pred, type(None))):\n",
    "            plt.title('Image: ' + str(indices[index-1]))           \n",
    "        elif (isinstance(emotion_nms_org, type(None)) & ~isinstance(emotion_nms_pred, type(None))):\n",
    "            plt.title('Image: ' + str(indices[index-1]) + '\\n' + 'Predicted emotion:' + emotion_nms_pred[indices[index-1]])\n",
    "        elif (~isinstance(emotion_nms_org, type(None)) & isinstance(emotion_nms_pred, type(None))):\n",
    "             plt.title('Image: ' + str(indices[index-1]) + '\\n' + 'Original emotion: ' + emotion_nms_org[indices[index-1]])           \n",
    "        else:\n",
    "            plt.title('Image: ' + str(indices[index-1]) + '\\n' + 'Original emotion: ' + emotion_nms_org[indices[index-1]] + \n",
    "                      '\\n' + 'Predicted emotion:' + emotion_nms_pred[indices[index-1]])\n",
    "        show_image = imgs[number].reshape(48,48)\n",
    "        try:\n",
    "            plt.subplot(3,5, index + 1)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        plt.axis('off')\n",
    "#         plt.tight_layout()\n",
    "        plt.imshow(show_image, cmap='gray')\n",
    "        \n",
    "\n",
    "show(images, emotion_nms_org= data['emotion_name'])\n",
    "\n",
    "\n",
    "# Standarizing images\n",
    "each_pixel_mean = images.mean(axis=0)\n",
    "each_pixel_std = np.std(images, axis=0)\n",
    "images = np.divide(np.subtract(images,each_pixel_mean), each_pixel_std)\n",
    "\n",
    "\n",
    "image_pixels = images.shape[1]\n",
    "image_width = image_height = np.ceil(np.sqrt(image_pixels)).astype(np.uint8)\n",
    "labels_flat = data[\"emotion\"].values.ravel()\n",
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "\n",
    "\n",
    "# Function for creating zero/ones matrix indicating image label\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[[index_offset + labels_dense.ravel()]] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "\n",
    "labels = dense_to_one_hot(labels_flat, labels_count)\n",
    "labels = labels.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(images.shape[0], 48, 48, 1)\n",
    "images = images.astype('float32')\n",
    "\n",
    "# Splitting images and labels into training, validation and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, shuffle = False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fvVfvlpXUs65"
   },
   "outputs": [],
   "source": [
    "#construct CNN structure\n",
    "model = Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', input_shape=(48,48,1), bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', input_shape=(48,48,1), bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "          \n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# #4th convolution layer\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "#fully connected neural networks\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(labels_count, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "f0DK4TmHUs6-"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training CNN using Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1074
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 292308,
     "status": "ok",
     "timestamp": 1523867019418,
     "user": {
      "displayName": "Łukasz Zawieska",
      "photoUrl": "//lh4.googleusercontent.com/-SOS7Ol5qfEA/AAAAAAAAAAI/AAAAAAAABh4/xJ9cAj7pBag/s50-c-k-no/photo.jpg",
      "userId": "112181072187986880314"
     },
     "user_tz": -120
    },
    "id": "WqJ6x2nPUs7A",
    "outputId": "a3b7d09b-ed7c-49cb-8f06-0c70cc13fac9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Specifying parameters for Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=40,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False,\n",
    "    zoom_range = 0.05)  # zoom images in range [1 - zoom_range, 1+ zoom_range]\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "# Saving model each time it achieves lower loss on the validation set\n",
    "filepath='Model.{epoch:02d}-{val_acc:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir='./logs')\n",
    "\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train,\n",
    "                    batch_size=32),\n",
    "                    nb_epoch=300,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    steps_per_epoch=X_train.shape[0]/32,\n",
    "                    callbacks=[checkpointer,tensorboard]\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading best model and exploring the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('Best_model_6759OffTest.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model2.evaluate(np.array(X_test), np.array(y_test), batch_size=1024)\n",
    "print(\"Loss: \" + str(scores[0]))\n",
    "print(\"Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(history.history).to_csv(\"history_val1.csv\")\n",
    "history = pd.read_csv('history.csv', usecols = ['acc','loss','val_acc','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1523868120543,
     "user": {
      "displayName": "Łukasz Zawieska",
      "photoUrl": "//lh4.googleusercontent.com/-SOS7Ol5qfEA/AAAAAAAAAAI/AAAAAAAABh4/xJ9cAj7pBag/s50-c-k-no/photo.jpg",
      "userId": "112181072187986880314"
     },
     "user_tz": -120
    },
    "id": "t9sfZi8gUs7I",
    "outputId": "ebdd949b-80ce-4d69-e1ca-3e093abc0bbd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10)) \n",
    "plt.plot(history['acc'])\n",
    "plt.plot(history['val_acc'])\n",
    "plt.title('model accuracy', fontsize = 18)\n",
    "plt.ylabel('accuracy', fontsize = 18)\n",
    "plt.xlabel('epoch', fontsize = 18)\n",
    "plt.legend(['train', 'test'], loc='upper left', fontsize = 16)\n",
    "plt.tick_params(axis='both', labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1523868146378,
     "user": {
      "displayName": "Łukasz Zawieska",
      "photoUrl": "//lh4.googleusercontent.com/-SOS7Ol5qfEA/AAAAAAAAAAI/AAAAAAAABh4/xJ9cAj7pBag/s50-c-k-no/photo.jpg",
      "userId": "112181072187986880314"
     },
     "user_tz": -120
    },
    "id": "tgml8vqzUs7M",
    "outputId": "89ff582b-df7f-4678-8399-5973cb55d116"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10)) \n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss', fontsize = 18)\n",
    "plt.ylabel('loss', fontsize = 18)\n",
    "plt.xlabel('epoch', fontsize = 18)\n",
    "plt.ylim(0.9,2)\n",
    "plt.legend(['train', 'test'], loc='upper left', fontsize = 16)\n",
    "plt.tick_params(axis='both', labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11444,
     "status": "ok",
     "timestamp": 1523868265564,
     "user": {
      "displayName": "Łukasz Zawieska",
      "photoUrl": "//lh4.googleusercontent.com/-SOS7Ol5qfEA/AAAAAAAAAAI/AAAAAAAABh4/xJ9cAj7pBag/s50-c-k-no/photo.jpg",
      "userId": "112181072187986880314"
     },
     "user_tz": -120
    },
    "id": "32C1wIfwUs7Q",
    "outputId": "d65b253c-eda9-4fec-d65a-3c8f1c9373a5"
   },
   "outputs": [],
   "source": [
    "def predict_classes(model, test_imgs, test_labels, emotions_dict,  batch_size  = 32):    \n",
    "\n",
    "    # Predict class of image using trained model\n",
    "    class_pred = model.predict(test_imgs, batch_size = batch_size)\n",
    "\n",
    "    # Convert vector of zeros and ones to label\n",
    "    labels_pred = np.argmax(class_pred,axis=1)\n",
    "    true_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "    # Boolean array that indicates whether the predicted label is the true label\n",
    "    correct = labels_pred == true_labels\n",
    "    \n",
    "    # Converting array of labels into emotion names\n",
    "    pred_emotion_names = pd.Series(labels_pred).map(emotions_dict)\n",
    "    \n",
    "    results = {'Predicted_label': labels_pred, 'Predicted_emotion': pred_emotion_names, 'Is_correct' : correct}\n",
    "    results = pd.DataFrame(results)\n",
    "    return correct, results\n",
    "\n",
    "\n",
    "\n",
    "def visualize_predictions(images_test, label_names, correct_arr, valid = True):\n",
    "    \n",
    "    if valid == True:\n",
    "        correct = np.array(np.where(correct_arr == True))[0]\n",
    "        # Plot 15 randomly selected and correctly predicted images\n",
    "        show(images_test, emotion_nms = label_names, random = False, indices = correct)\n",
    "    else:\n",
    "        incorrect = np.array(np.where(correct_arr == False))[0]\n",
    "        # Plot 15 randomly selected and wrongly predicted images\n",
    "        show(images_test, emotion_nms = label_names, random = False, indices = incorrect)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, results_df = predict_classes(model2, X_test, y_test, emotions_names, batch_size = 1024)\n",
    "results_df['Original_label'] = data['emotion'][32298:].values\n",
    "results_df['True_emotion'] = results_df['Original_label'].map(emotions_names)\n",
    "results_df[['Original_label', 'Predicted_label', 'True_emotion', 'Predicted_emotion', 'Is_correct']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(images_test, results_df['True_emotion'], correct, valid = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[37:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    show_image = img.reshape(48,48)\n",
    "    plt.imshow(show_image, cmap=cm.binary)\n",
    "    plt.imshow(show_image, cmap='gray')\n",
    "\n",
    "show(images[-1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "fer_1st_model.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
